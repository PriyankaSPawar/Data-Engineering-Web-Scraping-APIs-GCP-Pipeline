# Data-Engineering : Web Scraping using APIs & creation of Data Pipeline on Google Cloud Platform(GCP)

## DataScience Bootcamp Project 4 : WBS Coding School
Welcome to my fourth data engineering project! This time I am working on Gans —the e-scooter renting company— as a Data Engineer. This time I will work on data extraction with external sources, clean & transform it into databse and load it on cloud data pipeline. The severity of these tasks will require me to use **Web Scrapping**, **APIs**, **Google Cloud Platform (GCP)**.

## Objective 
To collect data from external sources that can potentially help Gans to anticipate as much as possible e-scooter movements.

## Project Overview 
Gans is a startup developing an e-scooter-sharing system. It aspires to operate in the most populour cities in Germany. With the help of Data Engineering techniques such as Web scraping, APIs, MySQL databases, and Creation od data pipeline on cloud, GANS hopes that they can make a strategy for movement of e-scooters efficiently.

## Challenges:
1. Collect data, transform it and store it in database.
2. Assemble and automate a data pipeline in the cloud.

## Tasks:
- Perform web scrapping by using programs or scripts to crawl websites, interpret HTML code, and extract specific information about cities(population,latitude,longitude,etc.)
- Use API to collect Weather & Flights data of the cities.
- Build a database using MySQL to store the collected information & use it as a backbone of data acquisition.
- Build a local pipeline from above data sources.
- Using Cloud MySQL create a database on cloud then using Cloud Functions & Scheduler automate the pipeline in the cloud.

## Flow of Project :

**Phase 1**
![Phase 1](https://github.com/PriyankaSPawar/DataEngineering-WebScraping-APIs-GCP-Pipeline/assets/168557945/ab19a0e9-d3df-4ea3-a0e7-87949b878954)

**Phase 2**

![Phase 2](https://github.com/PriyankaSPawar/DataEngineering-WebScraping-APIs-GCP-Pipeline/assets/168557945/9273b72f-03a2-4d54-80e1-2bc94e12a92f)

## Deliverables 
Preparation of an article on Medium which shows insights from the project, challenges, and solutions encountered throughout the process and more important to share valuable knowledge and tips for those who wish to embark on similar data pipeline projects using GCP. 

## Skills & Tools
1. Web scraping (Using BeautifulSoup)
2. APIs
3. Jupyter
4. MySQL (SQLAlchemy for interaction between MySql & Python)
5. Google Cloud Platform

## Data Files
1. Cleaned notebooks of Cities,Weather,Flights,Airports.
2. Data Script file for creation of database in SQL.
3. Weather Function notebook to automate in cloud.
4. Database Schema to get an idea about data connectivity.


